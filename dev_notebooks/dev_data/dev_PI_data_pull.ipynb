{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "13780175",
   "metadata": {},
   "source": [
    "# PI Tag Pulls - UNDER DEVELOPMENT\n",
    "This workbook is used to pull data and create an output table for the desired tags in either a csv or excel format.  Reason for the program:\n",
    "* Process engineers prefer Excel Workbooks,\n",
    "* Excel connection to PI is slow,\n",
    "* Excel crashes with large data pulls...and still needing data granularity.\n",
    "* Current MWR process use Alteryx with an output that is slow and the output is not user friendly.\n",
    "\n",
    " Process\n",
    " 1. The desired PI tags are first listed in an Excel workbook,\n",
    " 2. The program will extract the PI tags and use the PiConnect to connect to PI AF,\n",
    " 3. Data is extracted and placed into a flat file format\n",
    " 4. Data is output into another excel workbook/worksheet or csv file.  \n",
    "\n",
    " Potential additions to code: \n",
    " * Data from LIMS system is sent to PI.  Need to check if data points can be extracted without a interpolated value typically used in PI.  MWR currently extracts lab data using PowerBI. This is a visualization package and not a data manipulation package.  This could be developed as a separate file.\n",
    " * Data Type Column to select from PI or Lab data that is optional to send to the final report.\n",
    " * Units column that is optional to send to the final report\n",
    "\n",
    "Created by: TW  \n",
    "Created on: 2025-05-07  \n",
    "Environment: python_20240807"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2d83ae8",
   "metadata": {},
   "source": [
    "## Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "55833fa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#connect to PI Server\n",
    "import  PIconnect as PI\n",
    "from  PIconnect.PIConsts import SummaryType\n",
    "\n",
    "#manage time\n",
    "import pytz\n",
    "from datetime import datetime\n",
    "\n",
    "#standard libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "#other libraries\n",
    "import re\n",
    "import pathlib\n",
    "import xlsxwriter\n",
    "import openpyxl\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fb0d599",
   "metadata": {},
   "source": [
    "## Definitions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7027df9d",
   "metadata": {},
   "source": [
    "#### Extract PI Tags from Excel\n",
    "Convert an Excel spreadsheet that has the tag name and PI tag in to a dict. Note that process engineers love their lists of stuff in Excel spreadsheets.  Not efficient but that is easiest solution for them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "236783c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Add logging and unit tests\n",
    "###Add output of removed records\n",
    "def fn_PI_tags_from_excel(file_name: str ):\n",
    "    \"\"\"This function pulls PI_tags that are listed in an Excel Spreadsheet into a dataframe.  Excel spreadsheet should have 2 columns with the first column as the \"Tag Name\" and second column as the \"Tag\".\n",
    "\n",
    "    Args:\n",
    "        file_name (str): the name of hte excel workbook with the PI tags listed.  If it is not in the same directory, then the this is the file path for the Excel workbook.\n",
    "    \"\"\"\n",
    "    # Check for excel format\n",
    "    try:\n",
    "        df_PI_tags = pd.read_excel(file_name, sheet_name=\"data_dictionary\")\n",
    "    except:\n",
    "        raise TypeError(\"fn_PI_tags_from_excel: This must be an Excel file.  Check file name and path.\")\n",
    "\n",
    "    #clean PI tags\n",
    "    df_PI_tags_cln = df_PI_tags.dropna(axis=0, how=\"any\", subset=['Tag Name', 'Tag', 'Summary Type'])\n",
    "    df_PI_tags_cln = df_PI_tags_cln.drop_duplicates(keep=\"first\")\n",
    "\n",
    "    #create a df of removed records\n",
    "    df_PI_tags_removed = df_PI_tags.merge(df_PI_tags_cln, on=['Tag Name', 'Tag', 'Summary Type'], how=\"outer\", indicator= True)\n",
    "\n",
    "    df_PI_tags_removed = df_PI_tags_removed[df_PI_tags_removed['_merge'] != 'both']\n",
    "\n",
    "    df_PI_tags_removed = df_PI_tags_removed.drop(columns=['_merge'], axis=1)\n",
    "\n",
    "    #Reset Indexes\n",
    "    df_PI_tags_cln = df_PI_tags_cln.reset_index(drop=1)\n",
    "    df_PI_tags_removed = df_PI_tags_removed.reset_index(drop=1)\n",
    "\n",
    "    return df_PI_tags_cln, df_PI_tags_removed\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed7102f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tag Name</th>\n",
       "      <th>Tag</th>\n",
       "      <th>Summary Type</th>\n",
       "      <th>Data Type_x</th>\n",
       "      <th>Data Type_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Tag Name, Tag, Summary Type, Data Type_x, Data Type_y]\n",
       "Index: []"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fn_PI_tags_from_excel(file_name='PI_tag_list.xlsx')[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "769bd749",
   "metadata": {},
   "source": [
    "#### Generate dataframe with requested data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22d74473",
   "metadata": {},
   "outputs": [],
   "source": [
    "###  Needs logging and unit testing\n",
    "###### add sum_type in second row or onto tag name\n",
    "######## verify function  types\n",
    "\n",
    "def fn_create_results_dataframe(df: pd.DataFrame,\n",
    "                           start_time: str | datetime = \"-30d\",\n",
    "                           end_time: str | datetime = \"00:00:00\",\n",
    "                           interval: str = \"15m\"):\n",
    "                           #sum_type: str = 'AVERAGE' #sum type from spreadsheet instead of input\n",
    "\n",
    "    \"\"\"This function takes in a dataframe that contains a column with a 'tag name' and a second column with the 'tag'.  It creates a new dataframe that where the tag name becomes the name of the columns.  The tag is the path to the PI attribute which is used to look up the requested data.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): a dataframe that contain the 'tag name' in the first column and the (PI) 'tag' in the second column.\n",
    "\n",
    "        start_time ([str, datetime], optional): The start time for the data collection. Uses PI System Time abbreviations. Defaults to \"-30d\".\n",
    "\n",
    "        end_time ([str, datetime], optional): The end time for the data collection. Uses PI System Time abbreviations. Defaults to \"00:00\".\n",
    "\n",
    "        interval (str, optional): The  time interval between each record. Uses PI System Time abbreviations. Defaults to \"15m\".\n",
    "\n",
    "        sum_type (str, optional): The PI SummaryTypes. Some common values are: \"AVERAGE\", \"COUNT\", \"MAXIMUM\", \"MINIMUM\", \"RANGE\", \"STD_DEV\", and \"TOTAL\". Defaults to 'AVERAGE'.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: A dataframe that contains columns of data.  The column headers are the tag names provided and the data in each column is based upon the function parameter request.\n",
    "\n",
    "    Notes:\n",
    "        index is listed as local Denver timezone\n",
    "    \"\"\"\n",
    "\n",
    "    # # verify parameters\n",
    "\n",
    "    #### HASHED Sum_type as it is taken from  Excel Spreadsheet\n",
    "    # lst_sum_type = [\"ALL\", \"ALL_FOR_NON_NUMERIC\", \"AVERAGE\", \"COUNT\", \"MAXIMUM\", \"MINIMUM\", 'NONE', \"PERCENT_GOOD\", \"POP_STD_DEV\", \"RANGE\", \"STD_DEV\", \"TOTAL\", \"TOTAL_WITH_UOM\"]\n",
    "\n",
    "    # try:\n",
    "    #     lst_sum_type.index(sum_type)\n",
    "    # except:\n",
    "    #     raise TypeError(\"SummaryType is not from provided list.\")\n",
    "\n",
    "    #create result dataframe\n",
    "    df_results = pd.DataFrame()\n",
    "\n",
    "    #iterate through the tags\n",
    "    for i in df.index:\n",
    "        df_labels = pd.DataFrame()\n",
    "        \n",
    "        lbl = df.iloc[i,0] #tag names to pd column titles\n",
    "        tag = str(df.iloc[i,1]) # make ta a string for python readability\n",
    "        tag_split = tag.rsplit(sep=\"|\") #split the PI element and attribute\n",
    "        sum_type = df.iloc[i,2]\n",
    "        #collect the data from PI and adds to results dataframe\n",
    "        tag_data = db.descendant(tag_split[-2]).attributes[tag_split[-1]].summaries(start_time, end_time, interval, SummaryType.AVERAGE)\n",
    "\n",
    "        df_results[lbl] = tag_data\n",
    "\n",
    "    #Adjust to Denver timezone\n",
    "    df_results = df_results.tz_convert('America/Denver')\n",
    "    df_results.index = df_results.index.strftime('%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "    return df_results\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "92cc0938",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th>Level1</th>\n",
       "      <th>Name</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Level2</th>\n",
       "      <th>subheader1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Level1       Name\n",
       "Level2 subheader1\n",
       "0               1\n",
       "1               2\n",
       "2               3"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1 = pd.DataFrame({\"Name\": [1,2,3]})\n",
    "new_columns = pd.MultiIndex.from_tuples([\n",
    "    ('Name', 'subheader1'),  # Replace with your desired headers\n",
    "], names=['Level1', 'Level2'])\n",
    "df1.columns = new_columns\n",
    "df1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e346a6c",
   "metadata": {},
   "source": [
    "#### Create Excel or CSV Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39798b10",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Needs logging and unit testing\n",
    "\n",
    "##### \"new\" should not overwrite existing file - create numbering\n",
    "##### selection of different sheet name\n",
    "def fn_create_output_table(df: pd.DataFrame, file_name: str, file_output: str = 'existing',**kw):\n",
    "    \"\"\"This function takes in a dataframe and creates an output file.  The output file can be a csv or an excel workbook.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): A dataframe that contains the data to be output.\n",
    "\n",
    "        file_name (str): The name of the output file.  If it is not in the same directory, then the this is the file path for the output file.  Files should have a file extension for a csv or excel file (.csv, .xlsx, .xls)\n",
    "\n",
    "        file_output(str): Tells function to either add the data to a new excel file or append the data to the existing excel file. Options are \"new\" or \"existing\". Default is \"existing\".\n",
    "\n",
    "        if_sheet_exists (str, optional): Used only with existing excel files.  Determines what to do with data.  Select from \"error\", \"new\", \"replace\", \"overlay\".  See pandas ExcelWriter api for description. Default is \"replace\".\n",
    "\n",
    "    Returns:\n",
    "        This function outputs results to a csv or excel file.\n",
    "    \"\"\"\n",
    "    #validate filename type\n",
    "    if not isinstance(file_name, str):\n",
    "        raise TypeError('fn_create_output_table: file_name needs to be a string')\n",
    "\n",
    "    # default sheet_name\n",
    "    if not 'sheet_name' in kw.keys():\n",
    "        kw['sheet_name'] = \"PI Tag Output\"\n",
    "\n",
    "    #file_output validation and ExcelWriter adjustments\n",
    "    if file_output == \"existing\":\n",
    "        #default if_sheet_exists value\n",
    "        if not \"if_sheet_exists\" in kw.keys():\n",
    "            kw['if_sheet_exists'] = \"replace\"\n",
    "\n",
    "        #validate if_sheet_exists\n",
    "        if not kw['if_sheet_exists'] in ['error', 'new', 'replace', 'overlay']:\n",
    "            raise ValueError('fn_create_output_table: if_sheet_exists needs to be: error, new, replace, or overlay.')\n",
    "\n",
    "        md = \"a\" #mode for appending sheet\n",
    "\n",
    "    elif file_output == \"new\":\n",
    "        md = \"w+\" #mode for read/write\n",
    "\n",
    "        kw['if_sheet_exists'] = None #no if_sheet_exists for creating new file\n",
    "\n",
    "        #stop overwriting of an existing file\n",
    "        if os.path.isfile(file_name):\n",
    "            raise NameError(f\"fn_create_output_table: {file_name} already exists. Use different file name or change file_output to 'existing'.\")\n",
    "    else:\n",
    "        raise TypeError('fn_create_output_table: output_type is either exist or new.')\n",
    "\n",
    "    #extract file extension from file_name\n",
    "    file_ext = file_name.rsplit(sep=\".\")[-1].lower()\n",
    "\n",
    "    #validate file extension as excel or csv, and generate files\n",
    "    if file_ext == \"csv\":\n",
    "        df.to_csv(file_name, index=True)\n",
    "        print('csv works')\n",
    "    elif file_ext in ['xlsx', 'xls']:\n",
    "        with pd.ExcelWriter(file_name,\n",
    "                            engine='openpyxl',\n",
    "                            mode= md,\n",
    "                            if_sheet_exists=kw['if_sheet_exists']\n",
    "                            ) as writer:\n",
    "            df.to_excel(writer, sheet_name=kw['sheet_name'], index=True)\n",
    "    else:\n",
    "        raise TypeError('fn_create_output_table: file_name needs to have an csv or excel file extension type (.csv, .xlsx, .xls).')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "e7645b6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fn_create_output_table(df=df1, file_name='test.xlsx', file_output='existing', sheet_name=\"pig\", if_sheet_exists=\"new\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3be683fd",
   "metadata": {},
   "source": [
    "## Main function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "9549156d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected to APPLEPI_AF\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "<class 'pandas.core.frame.DataFrame'>\n"
     ]
    }
   ],
   "source": [
    "#Needs to be functionalized,\n",
    "#needs output to excel or a csv.\n",
    "#needs unit testing and logging.\n",
    "\n",
    "#inputs\n",
    "filename = \"PI_tag_list.xlsx\"\n",
    "\n",
    "\n",
    "# make connection to the PI database\n",
    "with PI.PIAFDatabase() as db:\n",
    "    print(f\"Connected to {db.server_name}\")\n",
    "\n",
    "#crate data frame of PI_tags\n",
    "df_PI_tags = fn_PI_tags_from_excel(file_name=filename)\n",
    "df_PI_tags_removed = df_PI_tags[1]\n",
    "df_PI_tags_cln = df_PI_tags[0]\n",
    "\n",
    "# PI request and result table creation\n",
    "df_results = fn_create_results_dataframe(df=df_PI_tags_cln)\n",
    "\n",
    "#save results to excel/csv\n",
    "fn_create_output_table(df=df_results, file_name=filename, file_output = 'existing')\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a39dea49",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>S Platte Temp</th>\n",
       "      <th>SHT1 flow</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2025-04-09 00:00:00</th>\n",
       "      <td>15.676</td>\n",
       "      <td>-1.825875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-04-09 00:15:00</th>\n",
       "      <td>15.676</td>\n",
       "      <td>-83.227764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-04-09 00:30:00</th>\n",
       "      <td>15.676</td>\n",
       "      <td>20.214584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-04-09 00:45:00</th>\n",
       "      <td>15.676</td>\n",
       "      <td>-24.640912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-04-09 01:00:00</th>\n",
       "      <td>15.676</td>\n",
       "      <td>-8.354832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-05-08 22:45:00</th>\n",
       "      <td>15.676</td>\n",
       "      <td>-0.206695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-05-08 23:00:00</th>\n",
       "      <td>15.676</td>\n",
       "      <td>-0.482275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-05-08 23:15:00</th>\n",
       "      <td>15.676</td>\n",
       "      <td>-0.256461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-05-08 23:30:00</th>\n",
       "      <td>15.676</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-05-08 23:45:00</th>\n",
       "      <td>15.676</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2880 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     S Platte Temp  SHT1 flow\n",
       "2025-04-09 00:00:00         15.676  -1.825875\n",
       "2025-04-09 00:15:00         15.676 -83.227764\n",
       "2025-04-09 00:30:00         15.676  20.214584\n",
       "2025-04-09 00:45:00         15.676 -24.640912\n",
       "2025-04-09 01:00:00         15.676  -8.354832\n",
       "...                            ...        ...\n",
       "2025-05-08 22:45:00         15.676  -0.206695\n",
       "2025-05-08 23:00:00         15.676  -0.482275\n",
       "2025-05-08 23:15:00         15.676  -0.256461\n",
       "2025-05-08 23:30:00         15.676   0.000000\n",
       "2025-05-08 23:45:00         15.676   0.000000\n",
       "\n",
       "[2880 rows x 2 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "032ac207",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a46d30c9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python_20240807",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
